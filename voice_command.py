import whisper
import pyaudio
import wave
import os
from pydub import AudioSegment
from pydub.effects import normalize
import pyttsx3
import sys
import openai
import warnings

warnings.filterwarnings(
    "ignore",
    message="FP16 is not supported on CPU; using FP32 instead"
)

# ë…¹ìŒ ì„¤ì •
FORMAT = pyaudio.paInt16
CHANNELS = 1
RATE = 44100
CHUNK = 1024
RECORD_SECONDS = 5
OUTPUT_FILENAME = "live_command.wav"
TEXT_FILENAME = "command.txt"

# Whisper ëª¨ë¸ ë¡œë“œ
model = whisper.load_model("medium")

# OpenAI API í‚¤ ì„¤ì •
openai.api_key = os.getenv("OPENAI_API_KEY")

# TTS ì—”ì§„ ì´ˆê¸°í™” (ì „ì—­)
tts = pyttsx3.init()
tts.setProperty("rate", 200)

def speak_prompt():
    prompt = (
        "ì•ˆë…•í•˜ì„¸ìš”, ì €ëŠ” ì—¬ëŸ¬ë¶„ì˜ ëˆˆì´ ë˜ì–´ ë¬¼ê±´ì„ ì°¾ëŠ” ê²ƒì„ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤. "
        "'ì–´ë–¤ ê²ƒì„ ì°¾ì•„ì¤˜' ë˜ëŠ” 'ì–´ë–¤ ê²ƒì„ ì–´ë””ì— ë‘ê³  ì‹¶ì–´' ë“±ì˜ í˜•ì‹ìœ¼ë¡œ ë§ì”€í•´ì£¼ì„¸ìš”. 5ì´ˆê°„ ë…¹ìŒë©ë‹ˆë‹¤."
    )
    tts.say(prompt)
    tts.runAndWait()

def record_audio():
    """ë§ˆì´í¬ë¡œ ìŒì„±ì„ ë…¹ìŒí•˜ê³  WAV íŒŒì¼ë¡œ ì €ì¥"""
    audio = pyaudio.PyAudio()
    stream = audio.open(format=FORMAT, channels=CHANNELS, rate=RATE, input=True, frames_per_buffer=CHUNK)

    print("- ìŒì„±ì„ ì…ë ¥í•˜ì„¸ìš”... (5ì´ˆ ë™ì•ˆ ë…¹ìŒ)")
    frames = [stream.read(CHUNK) for _ in range(0, int(RATE / CHUNK * RECORD_SECONDS))]

    print("ë…¹ìŒ ì™„ë£Œ! íŒŒì¼ ì €ì¥ ì¤‘...")

    stream.stop_stream()
    stream.close()
    audio.terminate()

    with wave.open(OUTPUT_FILENAME, 'wb') as wf:
        wf.setnchannels(CHANNELS)
        wf.setsampwidth(audio.get_sample_size(FORMAT))
        wf.setframerate(RATE)
        wf.writeframes(b''.join(frames))

    # ìŒëŸ‰ ì •ê·œí™”
    sound = AudioSegment.from_wav(OUTPUT_FILENAME)
    normalized_sound = normalize(sound)
    normalized_sound.export(OUTPUT_FILENAME, format="wav")


def is_move_intent(text: str) -> bool:
    """GPTì—ê²Œ ì´ ë¬¸ì¥ì´ ë¬¼ê±´ íƒìƒ‰/ì´ë™ ëª…ë ¹ì¸ì§€ yes/noë¡œë§Œ ë¬¼ì–´ë´„"""
    prompt = (
        "ì•„ë˜ ë¬¸ì¥ì´ ë¬¼ì²´ ì°¾ê¸° ë˜ëŠ” ë¬¼ì²´ ì´ë™ ëª…ë ¹ì¸ì§€ íŒë‹¨í•´ì¤˜. "
        "ëª…ë ¹ì´ë©´ â€˜yesâ€™, ì•„ë‹ˆë©´ â€˜noâ€™ë¡œë§Œ ëŒ€ë‹µí•´ì¤˜.\n\n"
        f"ë¬¸ì¥: \"{text.strip()}\""
    )
    resp = openai.ChatCompletion.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system",  "content": "ë‹¹ì‹ ì€ ë¬¸ì¥ ë¶„ë¥˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
            {"role": "user",    "content": prompt}
        ],
        temperature=0
    )
    answer = resp.choices[0].message.content.strip().lower()
    print(f"ì…ë ¥ ë¶„ë¥˜ ê²°ê³¼: {answer}")
    return answer.startswith("yes")


def transcribe_audio():
    """Whisperë¡œ ì˜¤ë””ì˜¤ íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ê³  ì €ì¥"""
    #print("ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ ì¤‘...")

    # í•œêµ­ì–´ ëª…ì‹œ
    result = model.transcribe(OUTPUT_FILENAME, language="ko")
    command_text = result["text"].strip()

    # ë§ ì•ˆ í–ˆì„ ë•Œ
    if len(command_text) < 3:
        tts.say("ìŒì„±ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ë§ì”€í•´ì£¼ì„¸ìš”.")
        print("ìŒì„± ê°ì§€ ì•ˆ ë¨. 5ì´ˆê°„ ì¬ë…¹ìŒ ì‹œì‘...")
        tts.runAndWait()
        return None

    # GPTë¡œ ëª…ë ¹ ì˜ë„ íŒë³„
    print("ğŸ§  GPTë¡œ ìŒì„± ì…ë ¥ ê²€ì‚¬ ì¤‘â€¦")
    try:
        if not is_move_intent(command_text):
            tts.say("'ì–´ë–¤ ê²ƒì„ ì°¾ì•„ì¤˜' ë˜ëŠ” 'ì–´ë–¤ ê²ƒì„ ì–´ë””ì— ë‘ê³  ì‹¶ì–´' ë“±ì˜ í˜•ì‹ìœ¼ë¡œ ë§ì”€í•´ì£¼ì„¸ìš”.")
            tts.runAndWait()
            return None
    except Exception as e:
        print("[GPT ì˜¤ë¥˜]", e)
        tts.say("ëª…ë ¹ì„ ì´í•´í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
        tts.runAndWait()
        return None

    with open(TEXT_FILENAME, "w", encoding="utf-8") as f:
        f.write(command_text)
    print(f"ë³€í™˜ëœ ëª…ë ¹ì–´ ì €ì¥ë¨: {command_text}")
    return command_text

def get_command():
    for attempt in range(3):
        record_audio()
        cmd = transcribe_audio()
        if cmd is not None:
            break # ì •ìƒ ë¬¸ì¥ì´ ë“¤ì–´ì™”ì„ ë•Œ loop íƒˆì¶œ
    else:
        # 3íšŒ ëª¨ë‘ ì‹¤íŒ¨
        tts.say("ì•Œ ìˆ˜ ì—†ëŠ” ì…ë ¥ì´ ë°˜ë³µë˜ì–´ ì‹œìŠ¤í…œì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        tts.runAndWait()
        sys.exit(0)

# def get_yes_no_response(prompt_text: str) -> bool:
#     """
#     prompt_text ë¥¼ TTSë¡œ ì½ê³ ,
#     ì‚¬ìš©ìì˜ ì‘ë‹µì„ ë…¹ìŒ â†’ Whisper ì „ì‚¬ â†’ GPTë¡œ ì˜ˆ/ì•„ë‹ˆì˜¤ ë¶„ë¥˜í•˜ì—¬
#     ê¸ì •(yes)ì´ë©´ True, ë¶€ì •(no)ì´ë©´ False ë°˜í™˜
#     """
#     # 1) ì§ˆë¬¸
#     tts.say(prompt_text)
#     tts.runAndWait()
#
#     # 2) ìµœëŒ€ 3íšŒ ì‹œë„
#     for _ in range(3):
#         record_audio()
#         # Whisper ì „ì‚¬
#         result = model.transcribe(OUTPUT_FILENAME, language="ko")["text"].strip()
#         if len(result) < 1:
#             tts.say("ì‘ë‹µì´ ì˜ ë“¤ë¦¬ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ë§ì”€í•´ì£¼ì„¸ìš”.")
#             tts.runAndWait()
#             continue
#
#         # 3) GPTë¡œ ì˜ˆ/ì•„ë‹ˆì˜¤ ë¶„ë¥˜
#         classification_prompt = (
#             "ë‹¤ìŒ ì‘ë‹µì´ â€˜ë„¤(ê¸ì •)â€™ì¸ì§€ â€˜ì•„ë‹ˆì˜¤(ë¶€ì •)â€™ì¸ì§€ íŒë‹¨í•´ ì£¼ì„¸ìš”. "
#             "ë°˜ë“œì‹œ â€˜yesâ€™ ë˜ëŠ” â€˜noâ€™ë§Œ ë‹µí•´ì£¼ì„¸ìš”.\n\n"
#             f"ì‘ë‹µ: \"{result}\""
#         )
#         resp = openai.ChatCompletion.create(
#             model="gpt-4o-mini",
#             messages=[
#                 {"role": "system", "content": "ë‹¹ì‹ ì€ ì˜ˆ/ì•„ë‹ˆì˜¤ ë¶„ë¥˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
#                 {"role": "user",   "content": classification_prompt}
#             ],
#             temperature=0
#         )
#         answer = resp.choices[0].message.content.strip().lower()
#         if answer.startswith("yes"):
#             return True
#         if answer.startswith("no"):
#             return False
#
#         # ê·¸ ì™¸ ì‘ë‹µì¼ ë•Œ
#         tts.say("ì˜ˆ ë˜ëŠ” ì•„ë‹ˆì˜¤ë¡œë§Œ ëŒ€ë‹µí•´ ì£¼ì„¸ìš”.")
#         tts.runAndWait()
#
#     # 3íšŒ ëª¨ë‘ ì´í•´ ë¶ˆê°€ ì‹œ ì¢…ë£Œ
#     tts.say("ì…ë ¥ì„ ì´í•´í•˜ì§€ ëª»í•´ ì‹œìŠ¤í…œì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
#     tts.runAndWait()
#     sys.exit(0)

def get_yes_no_response():
    """ë…¹ìŒâ†’Whisper ì „ì‚¬â†’â€˜ì˜ˆ/ì•„ë‹ˆì˜¤â€™ ì—¬ë¶€ íŒë‹¨ í›„ True/False ë¦¬í„´"""
    tts.say("ë‹¤ë¥¸ ë¬¼ê±´ì„ ì°¾ìœ¼ì‹œê² ìŠµë‹ˆê¹Œ? ì˜ˆ ë˜ëŠ” ì•„ë‹ˆì˜¤ë¡œ ëŒ€ë‹µí•´ì£¼ì„¸ìš”.")
    print("ë‹¤ë¥¸ ë¬¼ê±´ì„ ì°¾ìœ¼ì‹œê² ìŠµë‹ˆê¹Œ? ì˜ˆ/ì•„ë‹ˆì˜¤")

    tts.runAndWait()

    for attempt in range(3):
        # 1) ë…¹ìŒ
        record_audio()
        # 2) Whisper ì „ì‚¬
        result = model.transcribe(OUTPUT_FILENAME, language="ko")
        answer = result["text"].strip()
        # 3) ìŒì„± ì—†ìœ¼ë©´ ì¬ì‹œë„
        if not answer:
            tts.say("ìŒì„±ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ë§ì”€í•´ì£¼ì„¸ìš”.")
            tts.runAndWait()
            continue
        # 4) â€˜ì˜ˆâ€™ ê³„ì—´
        if any(w in answer for w in ["ë„¤", "ì˜ˆ", "ì‘", "ì–´"]):
            return True
        # 5) â€˜ì•„ë‹ˆì˜¤â€™ ê³„ì—´
        if any(w in answer for w in ["ì•„ë‹ˆ", "ì•„ë‹ˆìš”", "ì•„ë‹ˆì˜¤", "ì•„ë‹ˆì•¼"]):
            return False
        # 6) ê·¸ ì™¸ ì¬ì…ë ¥ ì•ˆë‚´
        tts.say("ì˜ ì¸ì‹í•˜ì§€ ëª»í–ˆì–´ìš”. â€˜ì˜ˆâ€™ ë˜ëŠ” â€˜ì•„ë‹ˆì˜¤â€™ë¡œë§Œ ë‹µí•´ì£¼ì„¸ìš”.")
        tts.runAndWait()

    # 3íšŒ ëª¨ë‘ ì‹¤íŒ¨ ì‹œ ì¢…ë£Œ
    tts.say("ì‘ë‹µì„ ì´í•´í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
    tts.runAndWait()
    sys.exit(0)


if __name__ == "__main__":
    speak_prompt()
    #record_audio()
    #transcribe_audio()

    get_command()
